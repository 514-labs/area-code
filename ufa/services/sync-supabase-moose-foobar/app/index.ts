import { Task, Workflow } from "@514labs/moose-lib";
import { SupabaseManager } from "./supabase/supabase-manager";
import { FooWithCDC, BarWithCDC, FooStatus } from "@workspace/models";

// Additional environment variables for service integrations
const ANALYTICS_BASE_URL =
  process.env.ANALYTICS_BASE_URL || "http://localhost:4100";
const RETRIEVAL_BASE_URL =
  process.env.RETRIEVAL_BASE_URL || "http://localhost:8083";

// Enhanced logging function
const logEvent = (
  event: string,
  table: string,
  payload: Record<string, unknown>
) => {
  const timestamp = new Date().toISOString();
  console.error(`\n[${timestamp}] ${event} event on ${table} table:`);
  console.log("Payload:", JSON.stringify(payload, null, 2));
  console.log("---");
};

// HTTP client for sending data to Elasticsearch via retrieval service
const sendDataToElasticsearch = async (
  type: "foo" | "bar",
  action: "index" | "delete",
  data: Record<string, unknown>
) => {
  console.log("Sending data to Elasticsearch:", type, action, data);
  const retrievalUrl = RETRIEVAL_BASE_URL;
  const url = `${retrievalUrl}/api/ingest/${type}`;

  try {
    console.log(`üîç Sending ${type} ${action} to Elasticsearch: ${url}`);

    const response = await fetch(url, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({ action, data }),
    });

    if (response.ok) {
      console.log(`‚úÖ Successfully sent ${type} ${action} to Elasticsearch`);
    } else {
      console.error(
        `‚ùå Failed to send ${type} ${action} to Elasticsearch:`,
        response.status,
        response.statusText
      );
      const errorText = await response.text();
      console.error("Response:", errorText);
    }
  } catch (error) {
    console.error(
      `‚ùå Error sending ${type} ${action} to Elasticsearch:`,
      error
    );
  }
};

// HTTP client for sending data to analytical pipelines
const sendDataToPipeline = async (
  type: "Foo" | "Bar",
  data: FooWithCDC | BarWithCDC
) => {
  const analyticsUrl = ANALYTICS_BASE_URL;
  const url = `${analyticsUrl}/ingest/${type}`;

  try {
    console.log(`üìä Sending ${type} data to analytical pipeline: ${url}`);

    // Helper function to safely format dates
    const formatDate = (dateValue: unknown): string => {
      if (dateValue instanceof Date) {
        return dateValue.toISOString();
      }
      if (typeof dateValue === "string" && dateValue) {
        const date = new Date(dateValue);
        return isNaN(date.getTime())
          ? new Date().toISOString()
          : date.toISOString();
      }
      // For missing dates (like in DELETE events), use current timestamp
      return new Date().toISOString();
    };

    // Format dates properly for JSON serialization
    const formattedData = {
      ...data,
      created_at: formatDate(data.created_at),
      updated_at: formatDate(data.updated_at),
      cdc_timestamp: data.cdc_timestamp.toISOString(),
    };

    const response = await fetch(url, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify(formattedData),
    });

    if (response.ok) {
      console.log(`‚úÖ Successfully sent ${type} data to analytical pipeline`);
    } else {
      console.error(
        `‚ùå Failed to send ${type} data to analytical pipeline:`,
        response.status,
        response.statusText
      );
      const errorText = await response.text();
      console.error("Response:", errorText);
    }
  } catch (error) {
    console.error(
      `‚ùå Error sending ${type} data to analytical pipeline:`,
      error
    );
  }
};

// Define interface for Supabase realtime payload
interface RealtimePayload {
  eventType: "INSERT" | "UPDATE" | "DELETE";
  new?: Record<string, unknown>;
  old?: Record<string, unknown>;
  commit_timestamp?: string;
}

// Business logic handlers for each table
async function handleFooChange(payload: RealtimePayload) {
  const { eventType, new: newRecord, old: oldRecord } = payload;

  // Determine the action based on event type and changes
  let action: "created" | "updated" | "deleted" | "activated" | "deactivated";
  // let changes: string[] = [];

  switch (eventType) {
    case "INSERT":
      if (!newRecord) {
        console.error("INSERT event missing new record");
        return;
      }
      action = "created";
      console.log(`üîî Business Logic: New foo "${newRecord.name}" created`);
      break;
    case "UPDATE":
      if (!newRecord || !oldRecord) {
        console.error("UPDATE event missing records");
        return;
      }
      // Determine specific update type
      if (oldRecord.is_active !== newRecord.is_active) {
        action = newRecord.is_active ? "activated" : "deactivated";
        console.log(`üîî Business Logic: Foo "${newRecord.name}" ${action}`);
      } else {
        action = "updated";
        console.log(`üîî Business Logic: Foo "${newRecord.name}" updated`);
      }

      // Track which fields changed
      // changes = Object.keys(newRecord).filter(
      //   (key) =>
      //     JSON.stringify(oldRecord[key]) !== JSON.stringify(newRecord[key])
      // );
      break;
    case "DELETE":
      if (!oldRecord) {
        console.error("DELETE event missing old record");
        return;
      }
      action = "deleted";
      console.log(`üîî Business Logic: Foo "${oldRecord.name}" was deleted`);
      break;
    default:
      console.warn(`Unknown event type: ${eventType}`);
      return;
  }

  try {
    const cdc_operation =
      eventType === "INSERT"
        ? "INSERT"
        : eventType === "UPDATE"
          ? "UPDATE"
          : "DELETE";

    // For DELETE events, use oldRecord; for INSERT/UPDATE, use newRecord
    const sourceData = eventType === "DELETE" ? oldRecord : newRecord;

    if (sourceData) {
      let fooPipelineData: FooWithCDC;

      if (eventType === "DELETE") {
        // For DELETE events, we only get the ID, so create a complete record with defaults
        fooPipelineData = {
          id: sourceData.id as string,
          name: "", // Unknown - record was deleted
          description: null,
          status: FooStatus.ARCHIVED, // Mark as archived since it's deleted
          priority: 0,
          is_active: false,
          metadata: {},
          tags: [],
          score: 0,
          large_text: "",
          created_at: new Date(), // Use current time as fallback
          updated_at: new Date(), // Use current time as fallback
          cdc_id: `foo-${sourceData.id}-${Date.now()}`,
          cdc_operation: "DELETE",
          cdc_timestamp: new Date(),
        };
      } else {
        // For INSERT/UPDATE events, we have the full record
        fooPipelineData = {
          ...sourceData,
          cdc_id: `foo-${sourceData.id}-${Date.now()}`,
          cdc_operation,
          cdc_timestamp: new Date(),
        } as FooWithCDC;
      }

      await sendDataToPipeline("Foo", fooPipelineData);
    }

    // Also send to Elasticsearch for search indexing
    if (eventType === "DELETE" && oldRecord) {
      await sendDataToElasticsearch("foo", "delete", { id: oldRecord.id });
    } else if (newRecord) {
      await sendDataToElasticsearch("foo", "index", newRecord);
    }
  } catch (error) {
    console.error("Error creating/sending FooThingEvent:", error);
  }
}

async function handleBarChange(payload: RealtimePayload) {
  const { eventType, new: newRecord, old: oldRecord } = payload;

  // Determine the action based on event type and changes
  let action: "created" | "updated" | "deleted" | "enabled" | "disabled";
  // let changes: string[] = [];

  switch (eventType) {
    case "INSERT":
      if (!newRecord) {
        console.error("INSERT event missing new record");
        return;
      }
      action = "created";
      console.log(
        `üîî Business Logic: New bar with value ${newRecord.value} created`
      );
      break;
    case "UPDATE":
      if (!newRecord || !oldRecord) {
        console.error("UPDATE event missing records");
        return;
      }
      // Determine specific update type
      if (oldRecord.is_enabled !== newRecord.is_enabled) {
        action = newRecord.is_enabled ? "enabled" : "disabled";
        console.log(`üîî Business Logic: Bar ${action}`);
      } else {
        action = "updated";
        console.log(`üîî Business Logic: Bar updated`);
      }

      // Track which fields changed
      // changes = Object.keys(newRecord).filter(
      //   (key) =>
      //     JSON.stringify(oldRecord[key]) !== JSON.stringify(newRecord[key])
      // );
      break;
    case "DELETE":
      if (!oldRecord) {
        console.error("DELETE event missing old record");
        return;
      }
      action = "deleted";
      console.log(
        `üîî Business Logic: Bar with value ${oldRecord.value} was deleted`
      );
      break;
    default:
      console.warn(`Unknown event type: ${eventType}`);
      return;
  }

  // Create and send BarThingEvent to analytics
  try {
    // Send to analytical pipeline for CDC processing
    const cdc_operation =
      eventType === "INSERT"
        ? "INSERT"
        : eventType === "UPDATE"
          ? "UPDATE"
          : "DELETE";

    // For DELETE events, use oldRecord; for INSERT/UPDATE, use newRecord
    const sourceData = eventType === "DELETE" ? oldRecord : newRecord;

    if (sourceData) {
      let barPipelineData: BarWithCDC;

      if (eventType === "DELETE") {
        // For DELETE events, we only get the ID, so create a complete record with defaults
        barPipelineData = {
          id: sourceData.id as string,
          foo_id: "", // Unknown - record was deleted
          value: 0,
          label: null,
          notes: null,
          is_enabled: false,
          created_at: new Date(), // Use current time as fallback
          updated_at: new Date(), // Use current time as fallback
          cdc_id: `bar-${sourceData.id}-${Date.now()}`,
          cdc_operation: "DELETE",
          cdc_timestamp: new Date(),
        };
      } else {
        // For INSERT/UPDATE events, we have the full record
        barPipelineData = {
          ...sourceData,
          cdc_id: `bar-${sourceData.id}-${Date.now()}`,
          cdc_operation,
          cdc_timestamp: new Date(),
        } as BarWithCDC;
      }

      await sendDataToPipeline("Bar", barPipelineData);
    }

    // Also send to Elasticsearch for search indexing
    if (eventType === "DELETE" && oldRecord) {
      await sendDataToElasticsearch("bar", "delete", { id: oldRecord.id });
    } else if (newRecord) {
      await sendDataToElasticsearch("bar", "index", newRecord);
    }
  } catch (error) {
    console.error("Error creating/sending BarThingEvent:", error);
  }
}

// Global references for cleanup
let globalChannel: any = null;
let globalSupabaseManager: SupabaseManager | null = null;

async function run(supabaseManager: SupabaseManager) {
  console.log("üöÄ Setting up realtime listeners...");

  // Get the initialized client and config
  const supabase = supabaseManager.getClient();
  const supabaseConfig = supabaseManager.getConfig();

  // Set up a single channel for all table changes
  const channel = supabase
    .channel("db-changes")
    .on(
      "postgres_changes",
      {
        event: "*",
        schema: supabaseConfig.dbSchema,
        table: "foo",
      },
      async (payload) => {
        logEvent("FOO CHANGE", "foo", payload);
        await handleFooChange(payload);
      }
    )
    .on(
      "postgres_changes",
      {
        event: "*",
        schema: supabaseConfig.dbSchema,
        table: "bar",
      },
      async (payload) => {
        logEvent("BAR CHANGE", "bar", payload);
        await handleBarChange(payload);
      }
    )
    .subscribe((status, error) => {
      // Log status with appropriate emoji/level based on status type
      const timestamp = new Date().toISOString();

      if (status === "SUBSCRIBED") {
        console.log(
          `‚úÖ [${timestamp}] Database changes listener status: ${status}`
        );
        console.log("üéâ Successfully connected to all database tables!");
        console.log("   - foo table: ‚úÖ");
        console.log("   - bar table: ‚úÖ");
      } else if (status === "CLOSED") {
        console.warn(
          `‚ùå [${timestamp}] Database changes listener status: ${status}`
        );
        console.warn("Connection to database tables closed");
      } else if (status === "CHANNEL_ERROR" || status === "TIMED_OUT") {
        console.error(
          `‚ùå [${timestamp}] Database changes listener ERROR: ${status}`
        );
        console.error("üö® Realtime connection failed!");
        console.error("Debugging information:");
        console.error("- Status:", status);
        console.error("- Supabase URL:", supabaseConfig.supabaseUrl);
        console.error("- Database schema:", supabaseConfig.dbSchema);
        console.error("- Tables being monitored: foo, bar");

        if (error) {
          console.error("- Error details:", error);
          console.error(
            "- Error message:",
            error.message || "No message available"
          );
          // Safely access extended error properties
          const errorWithDetails = error as Error & {
            code?: string;
            details?: string;
            hint?: string;
          };
          console.error(
            "- Error code:",
            errorWithDetails.code || "No code available"
          );
        } else {
          console.error("- No additional error details...");
        }
      } else {
        // Handle other statuses (CONNECTING, etc.)
        console.log(
          `üîÑ [${timestamp}] Database changes listener status: ${status}`
        );
      }

      // Always log error details if provided
      if (error) {
        console.error(`‚ùå [${timestamp}] Subscription error:`, error);
        if (error.message) {
          console.error("Error message:", error.message);
        }
        // Safely access extended error properties
        const errorWithDetails = error as Error & {
          details?: string;
          hint?: string;
        };
        if (errorWithDetails.details) {
          console.error("Error details:", errorWithDetails.details);
        }
        if (errorWithDetails.hint) {
          console.error("Error hint:", errorWithDetails.hint);
        }
      }
    });

  // Store channel reference for cleanup
  globalChannel = channel;

  // Handle graceful shutdown
  const cleanup = () => {
    console.log("\nüîÑ Cleaning up Supabase subscription...");
    if (channel) {
      channel.unsubscribe();
    }
    console.log("‚úÖ Cleanup complete");
  };

  process.on("SIGINT", cleanup);
  process.on("SIGTERM", cleanup);

  console.log("\nüéØ Supabase realtime listeners are now active!");
  console.log("Listening for changes on tables: foo, bar");
  console.log("The task will run indefinitely until stopped...");

  // Wait a bit to see initial connection status
  await new Promise((resolve) => setTimeout(resolve, 2000));
  console.log("üìä Initial connection setup complete");

  // Keep the task running indefinitely
  return new Promise<void>(() => {
    // This promise never resolves, keeping the task alive
    // The task will only end when the workflow is terminated
  });
}

async function onCancel() {
  console.log(
    "üõë Workflow cancellation requested - cleaning up Supabase subscriptions..."
  );

  // FIRST: Disable realtime replication triggers to stop new events at the source
  try {
    console.log("üõë Disabling realtime replication triggers...");

    // Use the global manager if available, otherwise create a new one
    const supabaseManager = globalSupabaseManager || new SupabaseManager();

    // Disable triggers FIRST to prevent any new events during cleanup
    await supabaseManager.disableRealtimeReplication();
    console.log("‚úÖ Realtime replication triggers disabled");
  } catch (error) {
    console.error("‚ö†Ô∏è  Could not disable realtime triggers:", error);
    console.log("‚ÑπÔ∏è  This is non-critical - continuing cleanup");
  }

  // THEN: Unsubscribe from the channel
  if (globalChannel) {
    try {
      console.log("üì° Unsubscribing from Supabase realtime channel...");
      await globalChannel.unsubscribe();
      console.log(
        "‚úÖ Successfully unsubscribed from Supabase realtime channel"
      );
      globalChannel = null;
    } catch (error) {
      console.error("‚ùå Error during Supabase channel cleanup:", error);
    }
  } else {
    console.log("‚ÑπÔ∏è  No active Supabase channel to clean up");
  }

  // FINALLY: Clear global references
  globalSupabaseManager = null;

  console.log("üßπ Cleanup complete - all resources released");
}

// Self-contained workflow initialization with proper checks and service waiting
async function runWithInitialization() {
  console.log("üöÄ Starting self-contained workflow initialization...");

  const supabaseManager = new SupabaseManager();

  // Store manager reference for cleanup
  globalSupabaseManager = supabaseManager;

  // Step 1: Initialize database and realtime with proper checks
  console.log("üîÑ Initializing database and realtime replication...");
  const dbStatus = await supabaseManager.initializeDatabase();

  if (!dbStatus.isConnected) {
    throw new Error(`‚ùå Database connection failed: ${dbStatus.error}`);
  }

  if (!dbStatus.isRealtimeConfigured) {
    throw new Error(`‚ùå Realtime setup failed: ${dbStatus.error}`);
  }

  console.log("‚úÖ All services verified and ready");

  return await run(supabaseManager);
}

// Long-running Supabase listener task
export const supabaseListenerTask = new Task<null, void>("supabase-listener", {
  run: runWithInitialization,
  onCancel,
  // Set a longer timeout for the long-running task
  timeout: "24h",
});

// Create the workflow with the combined task
export const supabaseListenerWorkflow = new Workflow("supabase-listener", {
  startingTask: supabaseListenerTask,
  // Run indefinitely until manually stopped
  timeout: "24h",
});
